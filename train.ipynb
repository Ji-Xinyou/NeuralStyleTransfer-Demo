{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from load_data import load_images\n",
    "from losses import content_loss, style_loss\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device('cuda:0')\n",
    "print('Current Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually set some macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get content and style images\n",
    "# CONTENT_IDX: 1: Neckarfront    2: sjtu entrance\n",
    "#              3: Shenzhen scene 4: Anime scene     5: anime\n",
    "# STYLE_IDX:   1: starry night   2: a colorful artwork with multiple geometries\n",
    "#              3: abstract art   4: Mondrian art\n",
    "CONTENT_IDX = 1\n",
    "STYLE_IDX = 1\n",
    "\n",
    "WEIGHT_CONTENT = 1\n",
    "WEIGHTS_STYLE = [1e11, 1e11, 1e11, 1e10, 1e10, 1e9, 1e9]\n",
    "# WEIGHTS_STYLE = [1e6] * len(layers)\n",
    "\n",
    "max_iter = 500\n",
    "show_iter = 50\n",
    "\n",
    "content_layers = [37]\n",
    "style_layers = [9, 12, 16, 22, 25, 29, 32]\n",
    "\n",
    "img_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image-loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    img_dir = os.getcwd() + '/Images/'\n",
    "    img_dirs = [img_dir, img_dir]\n",
    "    img_names = ['content{}.png'.format(CONTENT_IDX), 'style{}.png'.format(STYLE_IDX)]\n",
    "    imgs = [Image.open(img_dirs[i] + name) for i,name in enumerate(img_names)]\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pre-processing & post-processing transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = transforms.Compose([transforms.Scale(img_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to BGR\n",
    "                           transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961],\n",
    "                                                std=[1,1,1]),\n",
    "                           transforms.Lambda(lambda x: x.mul_(255)),\n",
    "                          ])\n",
    "recover = transforms.Compose([transforms.Lambda(lambda x: x.mul_(1./255)),\n",
    "                           transforms.Normalize(mean=[-0.40760392, -0.45795686, -0.48501961],\n",
    "                                                std=[1,1,1]),\n",
    "                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to RGB\n",
    "                           ])\n",
    "toPIL = transforms.Compose([transforms.ToPILImage()])\n",
    "\n",
    "def post(tensor): \n",
    "    tensor = recover(tensor)\n",
    "    tensor[tensor > 1] = 1    \n",
    "    tensor[tensor < 0] = 0\n",
    "    tensor = toPIL(tensor)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = load_images()\n",
    "imgs = [prep(img) for img in imgs]\n",
    "imgs = [Variable(img.unsqueeze(0).to(device)) for img in imgs]\n",
    "\n",
    "img_con, img_sty = imgs\n",
    "opt_img = Variable(img_con.data.clone(), requires_grad=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "deeaec1df6ed276a1cd9d77497d996f02bb9546587210d52500e128e56971336"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('stytrans': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
